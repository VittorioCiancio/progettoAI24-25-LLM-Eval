ğŸš€ LLM-EVAL: Valutazione Multidimensionale dei Modelli AI
LLM-EVAL Ã¨ un framework per la valutazione automatica dei modelli di Large Language Models (LLM) nelle conversazioni open-domain. Il progetto analizza le performance di modelli di intelligenza artificiale nella valutazione della qualitÃ  del dialogo, confrontando diverse metriche di correlazione con i giudizi umani.

ğŸ“Œ Obiettivi del progetto
ğŸ“Š Analisi della metrica LLM-EVAL: Comprendere la metodologia per la valutazione automatica dei dialoghi.
ğŸ¤– Confronto tra modelli di IA: Valutare e confrontare i modelli GPT4o-mini, GPT4o, Claude 3.5 e Claude 3.
ğŸ” Analisi dataset: Testare lâ€™impatto di dataset differenti sulla valutazione dei modelli.
ğŸ¯ Benchmark delle metriche: Utilizzare metriche avanzate (Spearman, Pearson, Kendall-Tau, Kappa di Cohen) per lâ€™analisi dei risultati.
ğŸ”§ Setup del progetto
Per eseguire i test e le valutazioni, clona il repository e installa le dipendenze:

bash
Copia
Modifica
git clone https://github.com/TuoUsername/LLM-EVAL.git
cd LLM-EVAL
pip install -r requirements.txt
âš ï¸ Nota: Alcune funzionalitÃ  richiedono credenziali API per interrogare modelli LLM. Assicurati di impostare il file .env con la chiave API corretta.

ğŸ“‚ Struttura del Repository
data/ â†’ Dataset utilizzati per la valutazione.
notebooks/ â†’ Notebook Jupyter per lâ€™analisi.
scripts/ â†’ Codice per la valutazione automatica.
results/ â†’ Output e report dei test.
ğŸš€ Esegui un test
Per valutare un modello, esegui:

bash
Copia
Modifica
python scripts/evaluate.py --model claude-3.5 --dataset convai2_data.json
I risultati verranno salvati nella cartella results/.

ğŸ“Š Risultati principali
ğŸ“Œ Modello piÃ¹ accurato: Claude 3.5 ha ottenuto la migliore accuratezza nella valutazione dei dialoghi.

ğŸ“Œ Dataset piÃ¹ adatto: I dataset FED e PC hanno fornito risultati piÃ¹ stabili rispetto a DSTC9, evidenziando lâ€™importanza delle annotazioni nei dati.

ğŸ“Œ Metriche di valutazione: La Correlazione di Spearman e il Kappa di Cohen sono risultate metriche efficaci per valutare la coerenza con i giudizi umani.

ğŸ“¢ Contributi e Futuri Sviluppi
Siamo aperti a contributi! Prossimi sviluppi:

âœ… Ottimizzazione dei prompt per ciascun modello.
âœ… Estensione del framework a nuovi dataset.
âœ… Implementazione di tecniche avanzate per la gestione dei bias.
Autori: Arcangeli Giovanni, Ciancio Vittorio, Di Maio Marco
ğŸ“… Data: 14/01/2025
